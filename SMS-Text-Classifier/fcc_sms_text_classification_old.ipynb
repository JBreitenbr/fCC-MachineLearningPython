{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-30T09:52:43.576513Z","iopub.execute_input":"2023-04-30T09:52:43.577432Z","iopub.status.idle":"2023-04-30T09:52:43.585959Z","shell.execute_reply.started":"2023-04-30T09:52:43.577376Z","shell.execute_reply":"2023-04-30T09:52:43.584292Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#get data files\n!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\ntrain_file_path = \"train-data.tsv\"\ntest_file_path = \"valid-data.tsv\"\ntrain=pd.DataFrame(pd.read_table(train_file_path))\ntrain.columns=[\"label\",\"txt\"]\ntest=pd.DataFrame(pd.read_table(test_file_path))\ntest.columns=[\"label\",\"txt\"]","metadata":{"execution":{"iopub.status.busy":"2023-04-30T09:52:49.447125Z","iopub.execute_input":"2023-04-30T09:52:49.447567Z","iopub.status.idle":"2023-04-30T09:52:49.470246Z","shell.execute_reply.started":"2023-04-30T09:52:49.447528Z","shell.execute_reply":"2023-04-30T09:52:49.468986Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncount_vector = CountVectorizer()\ntraining_data = count_vector.fit_transform(train[\"txt\"])\ntesting_data = count_vector.transform(test[\"txt\"])","metadata":{"execution":{"iopub.status.busy":"2023-04-30T09:52:57.058058Z","iopub.execute_input":"2023-04-30T09:52:57.058494Z","iopub.status.idle":"2023-04-30T09:52:57.169989Z","shell.execute_reply.started":"2023-04-30T09:52:57.058454Z","shell.execute_reply":"2023-04-30T09:52:57.168893Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nnaive_bayes = MultinomialNB()\nnaive_bayes.fit(training_data, train[\"label\"])","metadata":{"execution":{"iopub.status.busy":"2023-04-30T09:53:00.333971Z","iopub.execute_input":"2023-04-30T09:53:00.334428Z","iopub.status.idle":"2023-04-30T09:53:00.353463Z","shell.execute_reply.started":"2023-04-30T09:53:00.334387Z","shell.execute_reply":"2023-04-30T09:53:00.351872Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"MultinomialNB()"},"metadata":{}}]},{"cell_type":"code","source":"# function to predict messages based on model\n# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\ndef predict_message(pred_text):\n    vec_text=count_vector.transform([pred_text])\n    lst=[]\n    lst.append(naive_bayes.predict_proba(vec_text))\n    lst.append(naive_bayes.predict(vec_text))\n    return lst\npred_text = \"how are you doing today?\"\nprediction = predict_message(pred_text)\nprint(prediction)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T09:53:02.187436Z","iopub.execute_input":"2023-04-30T09:53:02.188288Z","iopub.status.idle":"2023-04-30T09:53:02.199325Z","shell.execute_reply.started":"2023-04-30T09:53:02.188247Z","shell.execute_reply":"2023-04-30T09:53:02.197861Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"[array([[9.99948451e-01, 5.15492672e-05]]), array(['ham'], dtype='<U4')]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Run this cell to test your function and model. Do not modify contents.\ndef test_predictions():\n  test_messages = [\"how are you doing today\",\n                   \"sale today! to stop texts call 98912460324\",\n                   \"i dont want to go. can we try it a different day? available sat\",\n                   \"our new mobile video service is live. just install on your phone to start watching.\",\n                   \"you have won Â£1000 cash! call to claim your prize.\",\n                   \"i'll bring it tomorrow. don't forget the milk.\",\n                   \"wow, is your arm alright. that happened to me one time too\"\n                  ]\n  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n  passed = True\n  for msg, ans in zip(test_messages, test_answers):\n    prediction = predict_message(msg)\n    if prediction[1] != ans:\n      passed = False\n  if passed:\n    print(\"You passed the challenge. Great job!\")\n  else:\n    print(\"You haven't passed yet. Keep trying.\")\ntest_predictions()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T09:53:06.157687Z","iopub.execute_input":"2023-04-30T09:53:06.158253Z","iopub.status.idle":"2023-04-30T09:53:06.173535Z","shell.execute_reply.started":"2023-04-30T09:53:06.158203Z","shell.execute_reply":"2023-04-30T09:53:06.172093Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"You passed the challenge. Great job!\n","output_type":"stream"}]}]}
